---
title: 数据挖掘40问
categories:
  - 零碎笔记
date: 2023-10-03 15:28:29
tags:
---
参见：[40 道数据挖掘面试真题，一次肝够 - 墨天轮 (modb.pro)](https://www.modb.pro/db/86064)


### 1. PCA中为什么要做正交变换

PCA的思想是把n维特征映射到k维上（k<n），这k维是新的正交特征，也被称为主成分。PCA的目的是选择最少的主成分。正交变换后，各主成分的坐标虽然改变，但是相对位置不变。

### 2. 给定一个数据集，这个数据集有缺失值，且这些缺失值分布在离中值有 1 个标准偏差的范围内。百分之多少的数据不会受到影响？为什么？
由于缺失值分布在中值附近，所以可以假设符合正态分布。
对于正态分布，68%的数据分布在离中值一个标准差的区间，95%的两个标准差，99%的三个标准差。
![](../../images/Pasted%20image%2020231003154923.png)
所以剩下的32%不会受到影响。
### 3. 给你一个癌症检测的数据集，你已经建好了分类模型，取得了96％的精度。如果不满意你的模型性能的话，你可以做些什么呢？
需要注意，癌症检测，属于**不平衡**数据集，更关注的是另外4%，所以只看精度指标并不合适。
还需要看灵敏度（真阳性率，即，预测为阳的，希望尽量是对的）和特异性（真阴性率，即预测是阴的，希望真的没问题）。
如果在4%上表现不好，可以进行：
1. 欠采样、过采样、SMOTE（Synthetic Minority Oversampling Technique即合成少数类过采样技术）
2. 通过概率验证和AUC-ROC曲线找到最佳阈值来找到预测阈值
3. 给分类分配权重，样本较少的分类给以较大的权重
4. 使用异常检测
### 4. 对于不平衡数据集，有什么应对方案？
1. 从训练集入手：过采样（小种类复制多次，易过拟合）、欠采样（大种类少采样，易欠拟合），EasyEnssemble（多次下采样，训练多个分类器）。
2. 从学习算法入手：数据合成（SMOTE）、数据加权、一分类或异常检测

### 5. 什么是 K-fold 交叉验证？
把原始数据随机分为K份，取其中一份作为验证集，另外K-1份作为训练集，从而进行K次重复实验，得到K个实验结果，用于评价模型的泛化能力。
### 6. 简述准确率(accuracy)、召回率(Recall)统计量的含义？
准确率是查准率，被认为是正确的，有多少被分对。
召回率是查全率，即所有的正样本中，有多少被识别出。
### 7. 简述 F 值(F-Measure)统计量的含义？


### 8. 简述 ROC 曲线统计量的含义？

### 9. 如何画出一个 ROC 曲线？

### 10. 简述 PR 曲线统计量的含义？

### 11. 什么是 SMOTE 算法？

### 12. 简述 G-mean 统计量的含义？

### 13. 简述 AUC 曲线统计量的含义？

### 14. SMOTE 算法有什么缺点？如何改进？

### 15. 简述什么是调和平均数并指出其应用及性质？

### 16. EasyEnsemble 算法？

### 17. 什么是凸包？

### 18. BalanceCascad 算法和 EasyEnsemble 有什么异同？

### 19. 你会在时间序列数据集上使用什么交叉验证技术？是用 k 倍或LOOCV？

### 20. 常见的过采样方法有哪些以用来应对样本不平衡问题？

### 21. 给你一个缺失值多于 30%的数据集？比方说，在 50 个变量中，有 8 个变量的缺失值都多于 30%。你对此如何处理？

### 22. 什么是协同过滤算法？

### 23. 当在解决一个分类问题时，出于验证的目的，你已经将训练集随机抽样地分成训练集和验证集。你对你的模型能在未看见的数据上有好的表现非常有信心，因为你的验证精度高。但是，在得到很差的精度后，你大失所望。什么地方出了错？

### 24. 在 k-means 或 kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？

### 25. 考虑到机器学习有这么多算法，给定一个数据集，你如何决定使用哪一个算法？

### 26. 什么时候正则化在机器学习中是有必要的？

### 27. 考虑到机器学习有这么多算法，给定一个数据集，你如何决定使用哪一个算法？

### 28. OLS 是用于线性回归，最大似然是用于逻辑回归。请解释以上描述。

### 29. 一个有 1000 列和 1 百万行的训练数据集。这个数据集是基于分类问题的。你来降低该数据集的维度以减少模型计算时间。你的机器内存有限，你会怎么做？（你可以自由做各种实际操作假设）

### 30. KNN 中的 K 是如何选取的？

### 31. 防止过拟合的方法有哪些？

### 32. 机器学习中为何要经常对数据做归一化？

### 33. 什么是欠采样和过采样？

### 34. 不平衡数据集处理中基于数据集的应对方案有哪些？

### 35. 二分类问题如何转化为一分类问题？

### 36. 如何通过增加惩罚项来提高稀有数据的预测准确率？

### 37. L1 和 L2 有什么区别？

### 38. CNN 最成功的应用是在 CV，那为什么 NLP 和 Speech 的很多问题也可以用 CNN 解出来？为什么 AlphaGo 里也用了 CNN？这几个不相关的问题的相似性在哪里？CNN 通过什么手段抓住了这个共性？

### 39. 实现对比 LSTM 结构推导，为什么比 RNN 好？

### 40. 请简要说说 EM 算法？


